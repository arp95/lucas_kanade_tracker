{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header files loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "print(\"Header files loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0001.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0002.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0003.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0004.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0005.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0006.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0007.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0008.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0009.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0010.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0011.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0012.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0013.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0014.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0015.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0016.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0017.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0018.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0019.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0020.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0021.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0022.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0023.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0024.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0025.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0026.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0027.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0028.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0029.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0030.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0031.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0032.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0033.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0034.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0035.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0036.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0037.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0038.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0039.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0040.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0041.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0042.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0043.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0044.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0045.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0046.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0047.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0048.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0049.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0050.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0051.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0052.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0053.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0054.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0055.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0056.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0057.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0058.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0059.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0060.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0061.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0062.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0063.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0064.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0065.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0066.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0067.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0068.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0069.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0070.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0071.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0072.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0073.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0074.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0075.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0076.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0077.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0078.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0079.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0080.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0081.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0082.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0083.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0084.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0085.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0086.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0087.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0088.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0089.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0090.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0091.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0092.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0093.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0094.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0095.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0096.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0097.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0098.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0099.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0100.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0101.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0102.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0103.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0104.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0105.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0106.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0107.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0108.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0109.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0110.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0111.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0112.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/0113.jpg']\n"
     ]
    }
   ],
   "source": [
    "path_of_images = \"/home/arpitdec5/Desktop/lucas_kanade_tracker/data/DragonBaby/img/*\"\n",
    "files  = glob.glob(path_of_images)\n",
    "files = sorted(files)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the grayscale image after converting it to lab colorspace\n",
    "def get_grayscale_image(image):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image: the input color image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    gray: grayscale image\n",
    "    \"\"\"\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 3)\n",
    "    \n",
    "    # return grayscale image\n",
    "    return gray\n",
    "\n",
    "\n",
    "# update the grayscale image, that is, normalize the pixel values with template image\n",
    "def update_grayscale_image(template_image, image):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    template_image: the template grayscale image whose ROI is given to us\n",
    "    image: the current grayscale frame \n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    image: the normalized current grayscale frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the mean of the template image and current frame and normalize\n",
    "    template_mean = np.mean(template_image)\n",
    "    mean = np.mean(image)\n",
    "    image = (image * (template_mean / mean)).astype(float)\n",
    "    \n",
    "    # return the normalized current grayscale frame\n",
    "    return image\n",
    "\n",
    "\n",
    "# computes error between images\n",
    "def compute_error_images(image_array1, image_array2):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image_array1: the template image array\n",
    "    image_array2: the current frame array\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    error: the error between each pixel of the template image and the current image\n",
    "    \"\"\"\n",
    "    \n",
    "    return (image_array1 - image_array2)\n",
    "\n",
    "\n",
    "# computes the coordinates of the ROI of interest\n",
    "def get_coordinates_array(x_range, y_range):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    x_range: array of two elements consisting of min_x and max_x of the ROI region\n",
    "    y_range: array of two elements consisting of min_y and max_y of the ROI region\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    coordinates_array: array of all the coordinates in the ROI region of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    # create coordinates array and push each possible coordinate in the ROI region\n",
    "    coordinates_array = np.zeros((3, int((x_range[1] - x_range[0] + 1) * (y_range[1] - y_range[0] + 1))))\n",
    "    count = 0\n",
    "    for y in range(int(y_range[0]), int(y_range[1]) + 1):\n",
    "        for x in range(int(x_range[0]), int(x_range[1]) + 1):\n",
    "            coordinates_array[0, count] = x\n",
    "            coordinates_array[1, count] = y\n",
    "            coordinates_array[2, count] = 1\n",
    "            count = count + 1\n",
    "            \n",
    "    # return the array\n",
    "    return coordinates_array\n",
    "\n",
    "\n",
    "# computes the new coordinates of the image wrt template image\n",
    "def get_new_image_coordinates(template_image_coordinates_array, p, x_range, y_range):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    template_image_coordinates_array: the coordinates of the ROI region of template image\n",
    "    p: the matrix to calculate the warped image\n",
    "    x_range: the range of x values for the image\n",
    "    y_range: the range of y values for the image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    new_gray_image_coordinates_array: the current frame ROI coordinates\n",
    "    new_rectangle_coordinates: the current frame rectangle coordinates (four: top-left, bottom-left, bottom-right, top-right)\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the rectangle coordinates of the ROI of template image\n",
    "    template_rectangle_coordinates = np.array([[x_range[0], x_range[0], x_range[1], x_range[1]], [y_range[0], y_range[1], y_range[1], y_range[0]], [1, 1, 1, 1]])\n",
    "\n",
    "    # get the affine matrix to get the warped image\n",
    "    affine_matrix = np.zeros((2, 3))\n",
    "    count = 0\n",
    "    for i in range(0, 3):\n",
    "        for j in range(0, 2):\n",
    "            affine_matrix[j, i] = p[count, 0]\n",
    "            count = count + 1\n",
    "    affine_matrix[0, 0] = affine_matrix[0, 0] + 1\n",
    "    affine_matrix[1, 1] = affine_matrix[1, 1] + 1\n",
    "    \n",
    "    # get new rectange coordinates\n",
    "    new_rectangle_coordinates = np.dot(affine_matrix, template_rectangle_coordinates)\n",
    "    \n",
    "    # get new coordinates\n",
    "    new_gray_image_coordinates_array = np.dot(affine_matrix, template_image_coordinates_array)\n",
    "    new_gray_image_coordinates_array = new_gray_image_coordinates_array.astype(int)\n",
    "    \n",
    "    # return the two arrays\n",
    "    return (new_gray_image_coordinates_array, new_rectangle_coordinates)\n",
    "    \n",
    "    \n",
    "# computes the pixel array\n",
    "def get_pixel_array(image, image_coordinates_array):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image: the input image\n",
    "    image_coordinates_array: the ROI region in the image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    pixel_array: the array consisting of pixels of the ROI region of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the pixel values of the ROI of the image\n",
    "    pixel_array = np.zeros((1, int(image_coordinates_array.shape[1])))\n",
    "    pixel_array[0, :] = image[image_coordinates_array[1, :], image_coordinates_array[0, :]]\n",
    "    \n",
    "    # return the pixel array\n",
    "    return pixel_array\n",
    "    \n",
    "    \n",
    "# compute the error in the p matrix\n",
    "def get_delta_p(error, steep_descent):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    error: the error between images\n",
    "    steep_descent: the steep descent value\n",
    "    \n",
    "    Outputs:\n",
    "    delta_p: the change in the p matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the sd_param and hessian matrix\n",
    "    sd_param_matrix = np.dot(steep_descent.T, error.T)\n",
    "    hessian_matrix = np.dot(steep_descent.T, steep_descent)\n",
    "    hessian_matrix_inv = np.linalg.pinv(hessian_matrix)\n",
    "    \n",
    "    # use the above two matrices to get the error in p matrix and return\n",
    "    delta_p = np.dot(hessian_matrix_inv, sd_param_matrix)\n",
    "    return delta_p    \n",
    "    \n",
    "    \n",
    "# compute the steep descent using two images and the coordinates of the ROI of two images\n",
    "def get_steep_descent(sobelx, sobely, template_image_coordinates_array, new_gray_image_coordinates_array):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    sobelx: the derivative along x-direction\n",
    "    sobely: the derivative along y-direction\n",
    "    template_gray_image_coordinates_array: the ROI coordinates of the template image\n",
    "    new_gray_image_coordinates_array: the ROI coordinates of the current frame\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    image: 6 images formed using above information\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the pixel array for sobelx\n",
    "    sobelx_pixel_array = get_pixel_array(sobelx, new_gray_image_coordinates_array)\n",
    "    \n",
    "    # get the pixel array for sobely\n",
    "    sobely_pixel_array = get_pixel_array(sobely, new_gray_image_coordinates_array)\n",
    "    \n",
    "    # get four images\n",
    "    image1 = sobelx_pixel_array * template_image_coordinates_array[0, :]\n",
    "    image2 = sobely_pixel_array * template_image_coordinates_array[0, :]\n",
    "    image3 = sobelx_pixel_array * template_image_coordinates_array[1, :]\n",
    "    image4 = sobely_pixel_array * template_image_coordinates_array[1, :]\n",
    "    \n",
    "    # return the six images\n",
    "    return np.vstack((image1, image2, image3, image4, sobelx_pixel_array, sobely_pixel_array)).T\n",
    "    \n",
    "    \n",
    "# lucas kanade algorithm\n",
    "def lucas_kanade_algorithm(template_gray_image, current_gray_image, x_range, y_range, p, thresh):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    template_gray_image: the grayscale template image\n",
    "    current_gray_image: the grayscale current frame\n",
    "    x_range: the array consisting of min_x and max_x values\n",
    "    y_range: the array consisting of min_y and max_y values\n",
    "    thresh: the threshold after which we need to break the loop\n",
    "    p: the matrix used for calculating the warped image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    new_rectangle_coordinates: the new ROI for the current frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the coordinates of the ROI for template image\n",
    "    template_image_coordinates_array = get_coordinates_array(x_range, y_range)\n",
    "    \n",
    "    # define p matrix, used for calculating the warped image for template image\n",
    "    p_template = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "    \n",
    "    # get the coordinates of the ROI in the new frame\n",
    "    (new_template_image_coordinates_array, new_rectangle_coordinates) = get_new_image_coordinates(template_image_coordinates_array, p_template, x_range, y_range)\n",
    "    \n",
    "    # get the pixel array of the template image\n",
    "    template_pixel_array = get_pixel_array(template_gray_image, new_template_image_coordinates_array)\n",
    "    \n",
    "    # compute derivatives around x and y directions for the current frame\n",
    "    sobelx = cv2.Sobel(current_gray_image, cv2.CV_64F, 1, 0, ksize = 3)\n",
    "    sobely = cv2.Sobel(current_gray_image, cv2.CV_64F, 0, 1, ksize = 3)\n",
    "    \n",
    "    # run algorithm\n",
    "    count = 0\n",
    "    while(True):\n",
    "        \n",
    "        # get the coordinates of the ROI in the new frame\n",
    "        (new_gray_image_coordinates_array, new_rectangle_coordinates) = get_new_image_coordinates(template_image_coordinates_array, p, x_range, y_range)\n",
    "        \n",
    "        # if new coordinates not in range, then break\n",
    "        if(count > 50 or new_gray_image_coordinates_array[0, 0] < 0 or new_gray_image_coordinates_array[1, 0] < 0 or new_gray_image_coordinates_array[0, new_gray_image_coordinates_array.shape[1] - 1] >= current_gray_image.shape[1] or new_gray_image_coordinates_array[1, new_gray_image_coordinates_array.shape[0] - 1] >= current_gray_image.shape[0]):\n",
    "            break\n",
    "            \n",
    "        # get the pixel array of the gray image\n",
    "        new_pixel_array = get_pixel_array(current_gray_image, new_gray_image_coordinates_array)\n",
    "        \n",
    "        # compute the error\n",
    "        error = compute_error_images(template_pixel_array, new_pixel_array)\n",
    "        \n",
    "        # compute steep descent\n",
    "        steep_descent = get_steep_descent(sobelx, sobely, template_image_coordinates_array, new_gray_image_coordinates_array)\n",
    "        \n",
    "        # get the delta_p\n",
    "        delta_p = get_delta_p(error, steep_descent)\n",
    "        \n",
    "        # get p norm and update p matrix\n",
    "        p_norm = np.linalg.norm(delta_p)\n",
    "        p = np.reshape(p, (6, 1))\n",
    "        delta_p = delta_p\n",
    "        p = p + delta_p\n",
    "        count = count + 1\n",
    "        \n",
    "        # if p_norm within thresh break\n",
    "        if(p_norm < thresh):\n",
    "            break\n",
    "            \n",
    "    # return the ROI needed for this frame\n",
    "    return (new_rectangle_coordinates, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bolt\n",
    "x_range = np.array([269, 303])\n",
    "y_range = np.array([75, 139])\n",
    "#x_range = np.array([251, 285])\n",
    "#y_range = np.array([74, 138])\n",
    "#240,72,34,64\n",
    "#x_range = np.array([240, 274])\n",
    "#y_range = np.array([72, 136])\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "template_image = cv2.imread(files[0])\n",
    "gray_template_image = get_grayscale_image(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car\n",
    "x_range = np.array([70, 177])\n",
    "y_range = np.array([51, 138])\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "template_image = cv2.imread(files[0])\n",
    "gray_template_image = get_grayscale_image(template_image)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 17,
>>>>>>> 3fcaa6ff0b80ac45ffcef0a73f8776a9c468ea72
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0458dc7b1d7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m83\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m148\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtemplate_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mgray_template_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_grayscale_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "# dragon baby\n",
    "x_range = np.array([160, 216])\n",
    "y_range = np.array([83, 148])\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "template_image = cv2.imread(files[0])\n",
    "gray_template_image = get_grayscale_image(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dragon baby\n",
    "x_range = np.array([160, 216])\n",
    "y_range = np.array([83, 148])\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "template_image = cv2.imread(files[0])\n",
    "gray_template_image = get_grayscale_image(template_image)\n",
    "\n",
    "# read files\n",
    "count = 0\n",
    "for file in glob.glob():\n",
    "    # read image\n",
    "    image = cv2.imread(file)\n",
    "    image_copy = image.copy()\n",
    "    \n",
    "    # initial frames\n",
    "    #if(count < 5):\n",
    "    #    image = cv2.rectangle(image, (int(x_range[0]), int(y_range[0])), (int(x_range[1]), int(y_range[1])), (0, 0, 255), 2)\n",
    "    #    cv2.imshow(\"Image\", image)\n",
    "    #    cv2.waitKey(0)\n",
    "    #    cv2.destroyAllWindows()\n",
    "    \n",
    "    # lucas kanade algo\n",
    "    gray = get_grayscale_image(image_copy)\n",
    "    gray = update_grayscale_image(gray_template_image, gray)\n",
    "    \n",
    "    (p, top_left, bottom_right) = lucas_kanade_algo(gray_template_image, gray, x_range, y_range, p, 0.01, 90, True, True)\n",
    "    count = count + 1\n",
    "    \n",
    "    #centroid_x = int((new_rectangle_coordinates[0, 0] + new_rectangle_coordinates[0, 2]) / 2.0)\n",
    "    #centroid_y = int((new_rectangle_coordinates[1, 0] + new_rectangle_coordinates[1, 2]) / 2.0)\n",
    "    #image = cv2.rectangle(image, (centroid_x - 28, centroid_y - 32), (centroid_x + 28, centroid_y + 32), (0, 0, 255), 2)\n",
    "    \n",
    "    image = cv2.rectangle(image, (int(top_left[0][0]), int(top_left[1][0])), (int(bottom_right[0][0]), int(bottom_right[1][0])), (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if(count > 55):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 57,
>>>>>>> 3fcaa6ff0b80ac45ffcef0a73f8776a9c468ea72
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_algo(template_frame, current_frame, x_range, y_range, p, thresh, constant, flag, add_brightness_weight):\n",
    "    \n",
    "    # compute the roi of the template\n",
    "    template_frame = template_frame[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "    \n",
    "    # compute derivatives around x and y directions for the current frame\n",
    "    sobelx = cv2.Sobel(current_frame, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "    sobely = cv2.Sobel(current_frame, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "    \n",
    "    count = 0\n",
    "    while(count <= 50):\n",
    "        count = count + 1\n",
    "        \n",
    "        # affine matrix\n",
    "        affine_mat = np.array([[1 + p[0][0], p[2][0], p[4][0]], [p[1][0], 1 + p[3][0], p[5][0]]], dtype = np.float32)\n",
    "        \n",
    "        # warp the image\n",
    "        warped_current_frame = cv2.warpAffine(current_frame, affine_mat, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        warped_current_frame = warped_current_frame[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "        \n",
    "        # warp the sobelx and sobely\n",
    "        warped_sobelx = cv2.warpAffine(sobelx, affine_mat, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        warped_sobely = cv2.warpAffine(sobely, affine_mat, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        warped_sobelx = warped_sobelx[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "        warped_sobely = warped_sobely[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "        warped_sobelx = warped_sobelx.reshape(-1, 1)\n",
    "        warped_sobely = warped_sobely.reshape(-1, 1)\n",
    "        \n",
    "        # calculate error value\n",
    "        error = (template_frame.astype(int) - warped_current_frame.astype(int)).reshape(-1, 1)\n",
    "        \n",
    "        # calculate steep descent value\n",
    "        count = 0\n",
    "        steep_descent = []\n",
    "        for y in range(y_range[0], y_range[1]):\n",
    "            for x in range(x_range[0], x_range[1]):\n",
    "                jacobian = [x * warped_sobelx[count][0], x * warped_sobely[count][0], y * warped_sobelx[count][0], y * warped_sobely[count][0], warped_sobelx[count][0], warped_sobely[count][0]]\n",
    "                steep_descent.append(jacobian)\n",
    "\n",
    "                if(add_brightness_weight and (error[count][0] < -40 or error[count][0] > 40)):\n",
    "                    error[count][0] = 0\n",
    "\n",
    "                count = count + 1\n",
    "        steep_descent = np.array(steep_descent)\n",
    "        \n",
    "        # calculate the hessian matrix and its inverse\n",
    "        sd_param_matrix = np.dot(steep_descent.T, error)\n",
    "        hessian_matrix = np.dot(steep_descent.T, steep_descent)\n",
    "        hessian_matrix_inv = np.linalg.pinv(hessian_matrix)\n",
    "        \n",
    "        # calculate delta_p and update p matrix\n",
    "        delta_p = np.dot(hessian_matrix_inv, sd_param_matrix)\n",
    "        p_norm = np.linalg.norm(delta_p)\n",
    "        p = np.reshape(p, (6, 1))\n",
    "        delta_p = constant * delta_p\n",
    "        p = p + delta_p\n",
    "        \n",
    "        if(flag and p_norm < thresh):\n",
    "            break\n",
    "        \n",
    "    # return the updated p and rectangle cooridnates\n",
    "    affine_mat = np.array([[1 + p[0][0], p[2][0], p[4][0]], [p[1][0], 1 + p[3][0], p[5][0]]], dtype = np.float32)\n",
    "    top_left = np.array([[x_range[0]], [y_range[0]], [1]])\n",
    "    bottom_right = np.array([[x_range[1]], [y_range[1]], [1]])\n",
    "    updated_top_left = np.dot(affine_mat, top_left)\n",
    "    updated_bottom_right = np.dot(affine_mat, bottom_right)\n",
    "    return (p, updated_top_left, updated_bottom_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
