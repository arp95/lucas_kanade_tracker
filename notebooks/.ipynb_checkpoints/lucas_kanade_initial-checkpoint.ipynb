{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test the video sequence for the Car4 dataset\n",
    "\n",
    "vid_seq = []\n",
    "\n",
    "# Iterate through all the images with .jpg extension\n",
    "for file in glob.glob('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\Car4\\\\img\\\\*.jpg'):\n",
    "    \n",
    "    #Read the images sequentially and append them in the vid_seq list\n",
    "    img = cv2.imread(file)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    vid_seq.append(img)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Car.avi',fourcc,5.0,size)\n",
    "\n",
    "for i in range(len(vid_seq)):\n",
    "    out.write(vid_seq[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test the video sequence for the Bolt dataset\n",
    "\n",
    "vid_seq = []\n",
    "\n",
    "# Iterate through all the images with .jpg extension\n",
    "for file in glob.glob('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\Bolt2\\\\img\\\\*.jpg'):\n",
    "    \n",
    "    # Read the images sequentially and append them in the vid_seq list\n",
    "    img = cv2.imread(file)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    vid_seq.append(img)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Bolt.avi',fourcc,5.0,size)\n",
    "\n",
    "for i in range(len(vid_seq)):\n",
    "    out.write(vid_seq[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test the video sequence for the BabyDragon dataset\n",
    "\n",
    "vid_seq = []\n",
    "\n",
    "# Iterate through all the images with .jpg extension\n",
    "for file in glob.glob('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\DragonBaby\\\\img\\\\*.jpg'):\n",
    "    \n",
    "    # Read the images sequentially and append them in the vid_seq list\n",
    "    img = cv2.imread(file)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    vid_seq.append(img)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('DragonBaby.avi',fourcc,5.0,size)\n",
    "\n",
    "for i in range(len(vid_seq)):\n",
    "    out.write(vid_seq[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Lucas Kanade metod for Affine Warp\n",
    "\n",
    "Warp the image $I$ to obtain $I(W[x,y];P)$\n",
    "\n",
    "Compute the error image $T(x)-I(W[x,y];P)$\n",
    "\n",
    "Warp the Gradient ${\\nabla{I}}$ with $(W[x,y];P)$\n",
    "\n",
    "Evaluate $\\frac{\\partial W}{\\partial P}$ at $([x,y];P)$\n",
    "\n",
    "Compute Steepest descent images ${\\nabla{I}}\\frac{\\partial W}{\\partial P}$\n",
    "\n",
    "Compute the Hessian Matrix $\\sum{({\\nabla{I}}\\frac{\\partial W}{\\partial P})}^{T}{{\\nabla{I}}\\frac{\\partial W}{\\partial P}}$\n",
    "\n",
    "Compute $\\sum{({\\nabla{I}}\\frac{\\partial W}{\\partial P})}{(T(x)-I(W[x,y];P))}$\n",
    "\n",
    "Compute ${\\Delta P}$\n",
    "\n",
    "$P{\\leftarrow}P+{\\Delta P}$\n",
    "\n",
    "Keep Iterating till the magnitude of ${\\Delta P}$ is negligible\n",
    "\n",
    "And also ${\\Delta P} = {({A}^{T}{A}})^{-1}{A^{T}}{b}$\n",
    "\n",
    "Here ${{A}^{T}{A}}$ is the Hessian Matrix that has been computed above and $A$ is the steepest descent image and $b$ is basicallty the error image that has been computed in step 2\n",
    "\n",
    "Affine Transform is given as ${\\begin{bmatrix} 1+{p_1} & {p_3} & {p_5}\\\\ {p_2} & {1+{p_4}} & {p_{6}}\\\\0&0&1\\\\\\end{bmatrix}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import affine_transform\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "# Get a grayscale image to input in the Lucas Kanade \n",
    "def get_grayscale_image(image):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    path_to_frame: The path to the frame that needs to be converted to a grayscale image: dtype=string\n",
    "    \n",
    "    \"\"\"\n",
    "    grayscale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    return grayscale\n",
    "\n",
    "# Reference: CMU Graduate computer Vision Course\n",
    "def crop_warped(image,rect):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    image: The warped image after performing an affine transformation\n",
    "    rect: The upleft and the truth bounding box\n",
    "    \n",
    "    \"\"\"\n",
    "    #warped = image[rect[1]:rect[1]+rect[3],rect[0]:rect[0]+rect[2]]\n",
    "    warped = image[rect[1]:rect[3], rect[0]:rect[2]]\n",
    "    return warped\n",
    "    \n",
    "def LucasKanadeAffine(image,template,rect,parameters=[0.0,0.0,0.0,0.0,0.0,0.0],threshold = 0.001, iterations = 50):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image: The input gray scale image\n",
    "    template: The template image\n",
    "    rect: The top left coordinates and the bottom right coordinates of the rectangle format--> [x1,y1,x2,y2]\n",
    "    threshold: The threshold that has been set to terminate the iterations as soon as delta p value approaches the threshold value\n",
    "    parameters: The initial parameters of the affine warp\n",
    "    iterations: Number of times the algorithm needs to run\n",
    "    \n",
    "    Returns:\n",
    "    p: Paramters of the affine warp matrix\n",
    "    Upper left bounding bax coordinates\n",
    "    Downright bounding box coordinates\n",
    "    \"\"\"\n",
    "    # Crop the region of interest from the template frame\n",
    "    template = crop_warped(template,rect)\n",
    "    \n",
    "    # Parameters of the affine matrix\n",
    "    p = parameters\n",
    "    \n",
    "    # Initial Affine Matrix\n",
    "    affine_matrix = np.array([[1.0,0.0,0.0],[0.0,1.0,0.0]])\n",
    "    \n",
    "    I = affine_matrix\n",
    "    \n",
    "    for iterations in range(iterations):\n",
    "        \n",
    "        # Warp the input image\n",
    "        warped_image = cv2.warpAffine(image,affine_matrix,image.shape)\n",
    "        \n",
    "        # Compute the error image\n",
    "        error_image = template - crop_warped(warped_image,rect)\n",
    "        \n",
    "        # Compute the image gradient in the x direction\n",
    "        sobelx = cv2.Sobel(image,cv2.CV_64F, dx = 1, dy = 0, ksize = 3)\n",
    "        \n",
    "        # Crop the Region of interest in our image gradient\n",
    "        sobel_x_cropped = crop_warped(sobelx,rect)\n",
    "        \n",
    "        # Compute the warped gradient in the x direction\n",
    "        sobel_x_warped = cv2.warpAffine(sobel_x_cropped, affine_matrix, sobel_x_cropped.shape)\n",
    "        \n",
    "        # Compute the image gradient in the y direction\n",
    "        sobely = cv2.Sobel(image,cv2.CV_64F, dx = 0, dy = 1, ksize = 3)\n",
    "        \n",
    "        # Crop the Region of interest in our image gradient\n",
    "        sobel_y_cropped = crop_warped(sobely,rect)\n",
    "        \n",
    "        # Compute the warped gradient in the y direction\n",
    "        sobel_y_warped = cv2.warpAffine(sobel_y_cropped, affine_matrix, sobel_y_cropped.shape)\n",
    "        \n",
    "        # Flatten out the warped gradients\n",
    "        sobel_x_warped = sobel_x_warped.reshape(-1,1)\n",
    "        sobel_y_warped = sobel_y_warped.reshape(-1,1)\n",
    "        \n",
    "        # Warp the image gradient with the warping function to produce an mx2 matrix\n",
    "        # Horizontally stack the derivatives\n",
    "        gradient_image_warped = np.hstack((sobel_x_warped,sobel_y_warped))\n",
    "        \n",
    "        # Evaluate the Jacobian and the steepest descent \n",
    "        count = 0\n",
    "        steepest_descent = []\n",
    "        for y in range(template.shape[1]):\n",
    "            for x in range(template.shape[0]):\n",
    "                \n",
    "                Jacobian = [x*sobel_x_warped[count][0], x*sobel_y_warped[count][0], y*sobel_x_warped[count][0], y*sobel_y_warped[count][0], sobel_x_warped[count][0], sobel_y_warped[count][0]]\n",
    "                steepest_descent.append(Jacobian)\n",
    "                count = count + 1\n",
    "        steepest_descent = np.array(steepest_descent)\n",
    "        \n",
    "        # Calculate the Hessian and inverse hessian from the steepest descent\n",
    "        sd_params_update = np.dot(steepest_descent.T,error_image)\n",
    "        hessian = np.dot(steepest_descent.T,steepest_descent)\n",
    "        hessian_inverse = np.linalg.inv(hessian)\n",
    "        \n",
    "        # Update delta p using solution for least squares\n",
    "        delta_p = np.dot(hessian_inverse, sd_params_update)\n",
    "        \n",
    "        # Update the parameters p\n",
    "        p = p + delta_p\n",
    "     \n",
    "        # Update the affine matrix with the newly generated parameters\n",
    "        affine_matrix = p.reshape(2,3) + I\n",
    "        \n",
    "        # Convergence test\n",
    "        if np.linalg.norm(delta_p) <= threshold:\n",
    "            break\n",
    "    \n",
    "    top_left_coordinates = np.array([[rect[1]],[rect[0]],[1]])\n",
    "    bottom_right_coordinates = np.array([[rect[1] + rect[3]], [rect[0]+rect[2]], [1]])\n",
    "    updated_top_left_coordinates = np.dot(affine_matrix, top_left_coordinates)\n",
    "    updated_bottom_right_coordinates = np.dot(affine_matrix, bottom_right_coordinates)\n",
    "    \n",
    "    return p, updated_top_left_coordinates, updated_bottom_right_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (6,2176) and (64,34) not aligned: 2176 (dim 1) != 64 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-afec20bce825>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Run the Lucas Kanade Algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mparamters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_left_coordinates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom_right_coordinates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLucasKanadeAffine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrayscale_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrayscale_template\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrect_bolt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Create a bounding box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fad0a2895692>\u001b[0m in \u001b[0;36mLucasKanadeAffine\u001b[1;34m(image, template, rect, parameters, threshold, iterations)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# Calculate the Hessian and inverse hessian from the steepest descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0msd_params_update\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteepest_descent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mhessian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteepest_descent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteepest_descent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mhessian_inverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (6,2176) and (64,34) not aligned: 2176 (dim 1) != 64 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Reading in the frames and performing the tracking\n",
    "# Take an initial bounding box for the car, dragon baby and bolt4\n",
    "\n",
    "rect_car = np.array([70,51,107+70,87+51])\n",
    "rect_bolt = np.array([269,75,34+269,64+75])\n",
    "rect_baby = np.array([160,83,56+160,65+83])\n",
    "\n",
    "# Create and test the video sequence for the Bolt dataset\n",
    "\n",
    "vid_seq = []\n",
    "files  = glob.glob('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\Bolt2\\\\img\\\\*.jpg')\n",
    "template = cv2.imread(files[0])\n",
    "grayscale_template = get_grayscale_image(template)\n",
    "\n",
    "# grayscale template image\n",
    "\n",
    "# The fourcc code\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "# Video writer object\n",
    "out = cv2.VideoWriter('Bolt.avi',fourcc,20.0, (480, 270))\n",
    "\n",
    "# Iterate through all the images with .jpg extension\n",
    "for file in files:\n",
    "    \n",
    "    image = cv2.imread(file)\n",
    "    image_copy = image.copy()\n",
    "    \n",
    "    # Input the gray scale image\n",
    "    grayscale_image = get_grayscale_image(image_copy)\n",
    "    \n",
    "    # Run the Lucas Kanade Algorithm\n",
    "    paramters, top_left_coordinates, bottom_right_coordinates = LucasKanadeAffine(grayscale_image,grayscale_template,rect_bolt,parameters=[0.0,0.0,0.0,0.0,0.0,0.0],threshold = 0.001, iterations = 20)\n",
    "    \n",
    "    # Create a bounding box\n",
    "    image = cv2.rectangle(image,(int(top_left_coordinates[0][0]),int(top_left_coordinates[1][0])), (int(bottom_right_coordinates[0][0]), int(bottom_right_coordinates[1][0])), (0, 0, 255), 2)\n",
    "    \n",
    "    # Write out the image\n",
    "    out.write(image)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame1 = cv2.imread('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\Bolt2\\\\img\\\\0001.jpg',0)\n",
    "frame2 = cv2.imread('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\Car4\\\\img\\\\0001.jpg',0)\n",
    "frame3 = cv2.imread('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\DragonBaby\\\\img\\\\0001.jpg',0)\n",
    "H, W = template.shape\n",
    "Jx = np.tile(np.linspace(0, W-1, W), (H, 1)).flatten().T\n",
    "Jy = np.tile(np.linspace(0, H-1, H), (W, 1)).T.flatten()\n",
    "x = 70\n",
    "y = 51\n",
    "length = 87\n",
    "width = 107\n",
    "rect = [70,51,107,87]\n",
    "frame2_copy = frame2.copy()\n",
    "frame2_copy = cv2.rectangle(frame2_copy,(x,y),(x+width,y+length),color = (255,0,0),thickness = 2)\n",
    "template = frame2_copy[rect[1]:rect[1]+rect[3],rect[0]:rect[0]+rect[2]]\n",
    "cv2.imshow('frame 2', frame2_copy)\n",
    "plt.imshow(template)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "template.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files  = glob.glob('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\Bolt2\\\\img\\\\*.jpg')\n",
    "grayscale_template = get_grayscale_image(files[0])\n",
    "\n",
    "cv2.imshow('template',grayscale_template)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-9668a792375d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrayscale_template\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "grayscale_template.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
