{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header files loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "print(\"Header files loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0001.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0002.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0003.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0004.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0005.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0006.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0007.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0008.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0009.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0010.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0011.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0012.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0013.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0014.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0015.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0016.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0017.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0018.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0019.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0020.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0021.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0022.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0023.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0024.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0025.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0026.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0027.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0028.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0029.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0030.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0031.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0032.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0033.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0034.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0035.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0036.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0037.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0038.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0039.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0040.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0041.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0042.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0043.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0044.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0045.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0046.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0047.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0048.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0049.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0050.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0051.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0052.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0053.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0054.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0055.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0056.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0057.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0058.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0059.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0060.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0061.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0062.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0063.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0064.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0065.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0066.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0067.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0068.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0069.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0070.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0071.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0072.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0073.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0074.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0075.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0076.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0077.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0078.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0079.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0080.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0081.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0082.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0083.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0084.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0085.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0086.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0087.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0088.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0089.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0090.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0091.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0092.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0093.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0094.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0095.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0096.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0097.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0098.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0099.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0100.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0101.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0102.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0103.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0104.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0105.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0106.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0107.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0108.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0109.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0110.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0111.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0112.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0113.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0114.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0115.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0116.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0117.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0118.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0119.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0120.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0121.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0122.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0123.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0124.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0125.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0126.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0127.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0128.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0129.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0130.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0131.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0132.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0133.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0134.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0135.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0136.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0137.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0138.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0139.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0140.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0141.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0142.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0143.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0144.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0145.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0146.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0147.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0148.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0149.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0150.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0151.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0152.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0153.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0154.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0155.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0156.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0157.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0158.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0159.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0160.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0161.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0162.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0163.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0164.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0165.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0166.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0167.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0168.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0169.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0170.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0171.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0172.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0173.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0174.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0175.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0176.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0177.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0178.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0179.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0180.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0181.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0182.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0183.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0184.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0185.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0186.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0187.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0188.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0189.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0190.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0191.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0192.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0193.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0194.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0195.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0196.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0197.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0198.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0199.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0200.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0201.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0202.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0203.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0204.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0205.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0206.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0207.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0208.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0209.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0210.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0211.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0212.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0213.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0214.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0215.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0216.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0217.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0218.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0219.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0220.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0221.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0222.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0223.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0224.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0225.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0226.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0227.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0228.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0229.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0230.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0231.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0232.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0233.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0234.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0235.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0236.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0237.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0238.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0239.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0240.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0241.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0242.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0243.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0244.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0245.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0246.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0247.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0248.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0249.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0250.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0251.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0252.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0253.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0254.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0255.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0256.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0257.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0258.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0259.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0260.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0261.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0262.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0263.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0264.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0265.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0266.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0267.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0268.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0269.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0270.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0271.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0272.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0273.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0274.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0275.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0276.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0277.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0278.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0279.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0280.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0281.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0282.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0283.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0284.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0285.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0286.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0287.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0288.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0289.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0290.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0291.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0292.jpg', '/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/0293.jpg']\n"
     ]
    }
   ],
   "source": [
    "path_of_images = \"/home/arpitdec5/Desktop/lucas_kanade_tracker/data/Bolt2/img/*\"\n",
    "files  = glob.glob(path_of_images)\n",
    "files = sorted(files)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import affine_transform\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "# Get a grayscale image to input in the Lucas Kanade \n",
    "def get_grayscale_image(image):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    path_to_frame: The path to the frame that needs to be converted to a grayscale image: dtype=string\n",
    "    \n",
    "    \"\"\"\n",
    "    grayscale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    return grayscale\n",
    "\n",
    "# Reference: CMU Graduate computer Vision Course\n",
    "def crop_warped(image,rect):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    image: The warped image after performing an affine transformation\n",
    "    rect: The upleft and the truth bounding box\n",
    "    \n",
    "    \"\"\"\n",
    "    #warped = image[rect[1]:rect[1]+rect[3],rect[0]:rect[0]+rect[2]]\n",
    "    warped = image[rect[1]:rect[3], rect[0]:rect[2]]\n",
    "    return warped\n",
    "    \n",
    "def LucasKanadeAffine(image,template,rect,p,threshold, iterations):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image: The input gray scale image\n",
    "    template: The template image\n",
    "    rect: The top left coordinates and the bottom right coordinates of the rectangle format--> [x1,y1,x2,y2]\n",
    "    threshold: The threshold that has been set to terminate the iterations as soon as delta p value approaches the threshold value\n",
    "    parameters: The initial parameters of the affine warp\n",
    "    iterations: Number of times the algorithm needs to run\n",
    "    \n",
    "    Returns:\n",
    "    p: Paramters of the affine warp matrix\n",
    "    Upper left bounding bax coordinates\n",
    "    Downright bounding box coordinates\n",
    "    \"\"\"\n",
    "    # Crop the region of interest from the template frame\n",
    "    template = crop_warped(template,rect)\n",
    "    \n",
    "    # Parameters of the affine matrix\n",
    "    #p = np.array([parameters]).reshape(-1,1)\n",
    "    \n",
    "    # Threshold for convergence\n",
    "    thresh = threshold\n",
    "    \n",
    "    # Initial Affine Matrix\n",
    "    #affine_matrix = np.array([[1.0,0.0,0.0],[0.0,1.0,0.0]])\n",
    "    \n",
    "    #I = affine_matrix\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        \n",
    "        # affine matrix\n",
    "        affine_matrix = np.array([[1 + p[0][0], p[2][0], p[4][0]], [p[1][0], 1 + p[3][0], p[5][0]]], dtype = np.float32)\n",
    "        \n",
    "        # Warp the input image\n",
    "        warped_image = cv2.warpAffine(image, affine_matrix, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        \n",
    "        # Compute the error image\n",
    "        error_image = template - crop_warped(warped_image, rect)\n",
    "        \n",
    "        # Compute the image gradient in the x direction\n",
    "        sobelx = cv2.Sobel(image, cv2.CV_64F, dx = 1, dy = 0, ksize = 3)\n",
    "        \n",
    "        # Compute the warped gradient in the x direction\n",
    "        sobel_x_warped = cv2.warpAffine(sobelx, affine_matrix, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        \n",
    "        # Crop the Region of interest in our image gradient\n",
    "        sobel_x_cropped = crop_warped(sobel_x_warped, rect)\n",
    "        \n",
    "        # Compute the image gradient in the y direction\n",
    "        sobely = cv2.Sobel(image, cv2.CV_64F, dx = 0, dy = 1, ksize = 3)\n",
    "        \n",
    "        # Compute the warped gradient in the y direction\n",
    "        sobel_y_warped = cv2.warpAffine(sobely, affine_matrix, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        \n",
    "        # Crop the Region of interest in our image gradient\n",
    "        sobel_y_cropped = crop_warped(sobel_y_warped, rect)\n",
    "        \n",
    "        # Flatten out the warped gradients\n",
    "        sobel_x_warped = sobel_x_warped.reshape(-1,1)\n",
    "        sobel_y_warped = sobel_y_warped.reshape(-1,1)\n",
    "        \n",
    "        # Warp the image gradient with the warping function to produce an mx2 matrix\n",
    "        # Horizontally stack the derivatives\n",
    "        gradient_image_warped = np.hstack((sobel_x_warped,sobel_y_warped))\n",
    "        \n",
    "        # Evaluate the Jacobian and the steepest descent \n",
    "        count = 0\n",
    "        steepest_descent = []\n",
    "        for y in range(rect[1],rect[3]):\n",
    "            for x in range(rect[0],rect[2]):\n",
    "                \n",
    "                Jacobian = [x*sobel_x_warped[count][0], x*sobel_y_warped[count][0], y*sobel_x_warped[count][0], y*sobel_y_warped[count][0], sobel_x_warped[count][0], sobel_y_warped[count][0]]\n",
    "                steepest_descent.append(Jacobian)\n",
    "                count = count + 1\n",
    "        steepest_descent = np.array(steepest_descent)\n",
    "        \n",
    "        # Calculate the Hessian and inverse hessian from the steepest descent\n",
    "        sd_params_update = np.dot(steepest_descent.T,error_image.reshape(-1,1))\n",
    "        hessian = np.dot(steepest_descent.T,steepest_descent)\n",
    "        hessian_inverse = np.linalg.inv(hessian)\n",
    "        \n",
    "        # Update delta p using solution for least squares\n",
    "        delta_p = np.dot(hessian_inverse, sd_params_update)\n",
    "        \n",
    "        # Update the parameters p\n",
    "        p = np.reshape(p, (6, 1))\n",
    "        p = p + delta_p\n",
    "        #print(f'After Iteration: {iterations} Value of p: {p}')\n",
    "        \n",
    "        # Update the affine matrix with the newly generated parameters\n",
    "        #affine_matrix = p.reshape(2,3) + I\n",
    "        print(iteration)\n",
    "        \n",
    "        # Convergence test\n",
    "        if np.linalg.norm(delta_p) <= thresh:\n",
    "            break\n",
    "    \n",
    "    top_left_coordinates = np.array([[rect[1]],[rect[0]],[1]])\n",
    "    bottom_right_coordinates = np.array([[rect[1] + rect[3]], [rect[0]+rect[2]], [1]])\n",
    "    updated_top_left_coordinates = np.dot(affine_matrix, top_left_coordinates)\n",
    "    updated_bottom_right_coordinates = np.dot(affine_matrix, bottom_right_coordinates)\n",
    "    \n",
    "    return p, updated_top_left_coordinates, updated_bottom_right_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the grayscale image after converting it to lab colorspace\n",
    "def get_grayscale_image(image):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image: the input color image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    gray: grayscale image\n",
    "    \"\"\"\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 5)\n",
    "    \n",
    "    # return grayscale image\n",
    "    return gray\n",
    "\n",
    "\n",
    "# update the grayscale image, that is, normalize the pixel values with template image\n",
    "def update_grayscale_image(template_image, image):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    template_image: the template grayscale image whose ROI is given to us\n",
    "    image: the current grayscale frame \n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    image: the normalized current grayscale frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the mean of the template image and current frame and normalize\n",
    "    template_mean = np.mean(template_image)\n",
    "    mean = np.mean(image)\n",
    "    image = (image * (template_mean / mean)).astype(float)\n",
    "    \n",
    "    # return the normalized current grayscale frame\n",
    "    return image\n",
    "\n",
    "\n",
    "# computes error between images\n",
    "def compute_error_images(image_array1, image_array2):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image_array1: the template image array\n",
    "    image_array2: the current frame array\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    error: the error between each pixel of the template image and the current image\n",
    "    \"\"\"\n",
    "    \n",
    "    return (image_array1 - image_array2)\n",
    "\n",
    "\n",
    "# computes the coordinates of the ROI of interest\n",
    "def get_coordinates_array(x_range, y_range):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    x_range: array of two elements consisting of min_x and max_x of the ROI region\n",
    "    y_range: array of two elements consisting of min_y and max_y of the ROI region\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    coordinates_array: array of all the coordinates in the ROI region of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    # create coordinates array and push each possible coordinate in the ROI region\n",
    "    coordinates_array = np.zeros((3, int((x_range[1] - x_range[0] + 1) * (y_range[1] - y_range[0] + 1))))\n",
    "    count = 0\n",
    "    for y in range(int(y_range[0]), int(y_range[1]) + 1):\n",
    "        for x in range(int(x_range[0]), int(x_range[1]) + 1):\n",
    "            coordinates_array[0, count] = x\n",
    "            coordinates_array[1, count] = y\n",
    "            coordinates_array[2, count] = 1\n",
    "            count = count + 1\n",
    "            \n",
    "    # return the array\n",
    "    return coordinates_array\n",
    "\n",
    "\n",
    "# computes the new coordinates of the image wrt template image\n",
    "def get_new_image_coordinates(template_image_coordinates_array, p, x_range, y_range):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    template_image_coordinates_array: the coordinates of the ROI region of template image\n",
    "    p: the matrix to calculate the warped image\n",
    "    x_range: the range of x values for the image\n",
    "    y_range: the range of y values for the image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    new_gray_image_coordinates_array: the current frame ROI coordinates\n",
    "    new_rectangle_coordinates: the current frame rectangle coordinates (four: top-left, bottom-left, bottom-right, top-right)\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the rectangle coordinates of the ROI of template image\n",
    "    template_rectangle_coordinates = np.array([[x_range[0], x_range[0], x_range[1], x_range[1]], [y_range[0], y_range[1], y_range[1], y_range[0]], [1, 1, 1, 1]])\n",
    "\n",
    "    # get the affine matrix to get the warped image\n",
    "    affine_matrix = np.zeros((2, 3))\n",
    "    count = 0\n",
    "    for i in range(0, 3):\n",
    "        for j in range(0, 2):\n",
    "            affine_matrix[j, i] = p[count, 0]\n",
    "            count = count + 1\n",
    "    affine_matrix[0, 0] = affine_matrix[0, 0] + 1\n",
    "    affine_matrix[1, 1] = affine_matrix[1, 1] + 1\n",
    "    \n",
    "    # get new rectange coordinates\n",
    "    new_rectangle_coordinates = np.dot(affine_matrix, template_rectangle_coordinates)\n",
    "    \n",
    "    # get new coordinates\n",
    "    new_gray_image_coordinates_array = np.dot(affine_matrix, template_image_coordinates_array)\n",
    "    new_gray_image_coordinates_array = new_gray_image_coordinates_array.astype(int)\n",
    "    \n",
    "    # return the two arrays\n",
    "    return (new_gray_image_coordinates_array, new_rectangle_coordinates)\n",
    "    \n",
    "    \n",
    "# computes the pixel array\n",
    "def get_pixel_array(image, image_coordinates_array):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    image: the input image\n",
    "    image_coordinates_array: the ROI region in the image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    pixel_array: the array consisting of pixels of the ROI region of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the pixel values of the ROI of the image\n",
    "    pixel_array = np.zeros((1, int(image_coordinates_array.shape[1])))\n",
    "    pixel_array[0, :] = image[image_coordinates_array[1, :], image_coordinates_array[0, :]]\n",
    "    \n",
    "    # return the pixel array\n",
    "    return pixel_array\n",
    "    \n",
    "    \n",
    "# compute the error in the p matrix\n",
    "def get_delta_p(error, steep_descent):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    error: the error between images\n",
    "    steep_descent: the steep descent value\n",
    "    \n",
    "    Outputs:\n",
    "    delta_p: the change in the p matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the sd_param and hessian matrix\n",
    "    sd_param_matrix = np.dot(steep_descent.T, error.T)\n",
    "    hessian_matrix = np.dot(steep_descent.T, steep_descent)\n",
    "    hessian_matrix_inv = np.linalg.pinv(hessian_matrix)\n",
    "    \n",
    "    # use the above two matrices to get the error in p matrix and return\n",
    "    delta_p = np.dot(hessian_matrix_inv, sd_param_matrix)\n",
    "    return delta_p    \n",
    "    \n",
    "    \n",
    "# compute the steep descent using two images and the coordinates of the ROI of two images\n",
    "def get_steep_descent(sobelx, sobely, template_image_coordinates_array, new_gray_image_coordinates_array):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    sobelx: the derivative along x-direction\n",
    "    sobely: the derivative along y-direction\n",
    "    template_gray_image_coordinates_array: the ROI coordinates of the template image\n",
    "    new_gray_image_coordinates_array: the ROI coordinates of the current frame\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    image: 6 images formed using above information\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the pixel array for sobelx\n",
    "    sobelx_pixel_array = get_pixel_array(sobelx, new_gray_image_coordinates_array)\n",
    "    \n",
    "    # get the pixel array for sobely\n",
    "    sobely_pixel_array = get_pixel_array(sobely, new_gray_image_coordinates_array)\n",
    "    \n",
    "    # get four images\n",
    "    image1 = sobelx_pixel_array * template_image_coordinates_array[0, :]\n",
    "    image2 = sobely_pixel_array * template_image_coordinates_array[0, :]\n",
    "    image3 = sobelx_pixel_array * template_image_coordinates_array[1, :]\n",
    "    image4 = sobely_pixel_array * template_image_coordinates_array[1, :]\n",
    "    \n",
    "    # return the six images\n",
    "    return np.vstack((image1, image2, image3, image4, sobelx_pixel_array, sobely_pixel_array)).T\n",
    "    \n",
    "    \n",
    "# lucas kanade algorithm\n",
    "def lucas_kanade_algorithm(template_gray_image, current_gray_image, x_range, y_range, p, thresh):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    template_gray_image: the grayscale template image\n",
    "    current_gray_image: the grayscale current frame\n",
    "    x_range: the array consisting of min_x and max_x values\n",
    "    y_range: the array consisting of min_y and max_y values\n",
    "    thresh: the threshold after which we need to break the loop\n",
    "    p: the matrix used for calculating the warped image\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    new_rectangle_coordinates: the new ROI for the current frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the coordinates of the ROI for template image\n",
    "    template_image_coordinates_array = get_coordinates_array(x_range, y_range)\n",
    "    \n",
    "    # define p matrix, used for calculating the warped image for template image\n",
    "    p_template = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "    \n",
    "    # get the coordinates of the ROI in the new frame\n",
    "    (new_template_image_coordinates_array, new_rectangle_coordinates) = get_new_image_coordinates(template_image_coordinates_array, p_template, x_range, y_range)\n",
    "    \n",
    "    # get the pixel array of the template image\n",
    "    template_pixel_array = get_pixel_array(template_gray_image, new_template_image_coordinates_array)\n",
    "    \n",
    "    # compute derivatives around x and y directions for the current frame\n",
    "    sobelx = cv2.Sobel(current_gray_image, cv2.CV_64F, 1, 0, ksize = 3)\n",
    "    sobely = cv2.Sobel(current_gray_image, cv2.CV_64F, 0, 1, ksize = 3)\n",
    "    \n",
    "    # run algorithm\n",
    "    count = 0\n",
    "    while(True):\n",
    "        \n",
    "        # get the coordinates of the ROI in the new frame\n",
    "        (new_gray_image_coordinates_array, new_rectangle_coordinates) = get_new_image_coordinates(template_image_coordinates_array, p, x_range, y_range)\n",
    "        \n",
    "        # if new coordinates not in range, then break\n",
    "        if(count > 50 or new_gray_image_coordinates_array[0, 0] < 0 or new_gray_image_coordinates_array[1, 0] < 0 or new_gray_image_coordinates_array[0, new_gray_image_coordinates_array.shape[1] - 1] >= current_gray_image.shape[1] or new_gray_image_coordinates_array[1, new_gray_image_coordinates_array.shape[0] - 1] >= current_gray_image.shape[0]):\n",
    "            break\n",
    "            \n",
    "        # get the pixel array of the gray image\n",
    "        new_pixel_array = get_pixel_array(current_gray_image, new_gray_image_coordinates_array)\n",
    "        \n",
    "        # compute the error\n",
    "        error = compute_error_images(template_pixel_array, new_pixel_array)\n",
    "        \n",
    "        # compute steep descent\n",
    "        steep_descent = get_steep_descent(sobelx, sobely, template_image_coordinates_array, new_gray_image_coordinates_array)\n",
    "        \n",
    "        # get the delta_p\n",
    "        delta_p = get_delta_p(error, steep_descent)\n",
    "        \n",
    "        # get p norm and update p matrix\n",
    "        p_norm = np.linalg.norm(delta_p)\n",
    "        p = np.reshape(p, (6, 1))\n",
    "        delta_p = delta_p\n",
    "        p = p + delta_p\n",
    "        count = count + 1\n",
    "        \n",
    "        # if p_norm within thresh break\n",
    "        if(p_norm < thresh):\n",
    "            break\n",
    "            \n",
    "    # return the ROI needed for this frame\n",
    "    return (new_rectangle_coordinates, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-259501caab73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Run the Lucas Kanade Algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_left_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom_right_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLucasKanadeAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayscale_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrayscale_template\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrect_bolt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Create a bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-349a825e34ed>\u001b[0m in \u001b[0;36mLucasKanadeAffine\u001b[0;34m(image, template, rect, p, threshold, iterations)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msd_params_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteepest_descent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mhessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteepest_descent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteepest_descent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mhessian_inverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Update delta p using solution for least squares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arpitdec5/.local/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arpitdec5/.local/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "rect_car = np.array([70,51,107+70,87+51])\n",
    "rect_bolt = np.array([269,75,34+269,64+75])\n",
    "rect_baby = np.array([160,83,56+160,65+83])\n",
    "\n",
    "# Create and test the video sequence for the Bolt dataset\n",
    "\n",
    "#files  = glob.glob('C:\\\\Users\\\\shant\\\\lucas_kanade_tracker\\\\data\\\\Bolt2\\\\img\\\\*.jpg')\n",
    "\n",
    "# grayscale template image\n",
    "template = cv2.imread(files[0])\n",
    "grayscale_template = get_grayscale_image(template)\n",
    "\n",
    "# List to append the frame sequences\n",
    "vid_seq = []\n",
    "\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "\n",
    "# Iterate through all the images with .jpg extension\n",
    "for file in files:\n",
    "    \n",
    "    image = cv2.imread(file)\n",
    "    image_copy = image.copy()\n",
    "    \n",
    "    # Input the gray scale image\n",
    "    grayscale_image = get_grayscale_image(image_copy)\n",
    "    \n",
    "    # Run the Lucas Kanade Algorithm\n",
    "    p, top_left_coordinates, bottom_right_coordinates = LucasKanadeAffine(grayscale_image,grayscale_template,rect_bolt, p,threshold = 0.001, iterations = 20)\n",
    "    \n",
    "    # Create a bounding box\n",
    "    image = cv2.rectangle(image,(int(top_left_coordinates[0][0]),int(top_left_coordinates[1][0])), (int(bottom_right_coordinates[0][0]), int(bottom_right_coordinates[1][0])), (0, 0, 255), 2)\n",
    "    \n",
    "    #vid_seq.append(image)\n",
    "\n",
    "# The fourcc code\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "# Video writer object\n",
    "#out = cv2.VideoWriter('Bolt.avi',fourcc,20.0, (480, 270))\n",
    "\n",
    "#for i in range(len(vid_seq)):\n",
    "#    out.write(vid_seq[i])\n",
    "#out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bolt\n",
    "x_range = np.array([269, 303])\n",
    "y_range = np.array([75, 139])\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "template_image = cv2.imread(files[0])\n",
    "gray_template_image = get_grayscale_image(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car\n",
    "x_range = np.array([70, 177])\n",
    "y_range = np.array([51, 138])\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "template_image = cv2.imread(files[0])\n",
    "gray_template_image = get_grayscale_image(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dragon baby\n",
    "x_range = np.array([160, 216])\n",
    "y_range = np.array([83, 148])\n",
    "p = np.array([[0, 0, 0, 0, 0, 0]]).T\n",
    "template_image = cv2.imread(files[0])\n",
    "gray_template_image = get_grayscale_image(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "count = 0\n",
    "for file in files:\n",
    "    # read image\n",
    "    image = cv2.imread(file)\n",
    "    image_copy = image.copy()\n",
    "    \n",
    "    # get grayscale image\n",
    "    gray = get_grayscale_image(image_copy)\n",
    "    #gray = update_grayscale_image(gray_template_image, gray)\n",
    "    \n",
    "    # run lucas-kanade algo\n",
    "    (p, top_left, bottom_right) = lucas_kanade_update(gray_template_image, gray, x_range, y_range, p, 0.01, 30, True)\n",
    "    count = count + 1\n",
    "    \n",
    "    #centroid_x = int((new_rectangle_coordinates[0, 0] + new_rectangle_coordinates[0, 2]) / 2.0)\n",
    "    #centroid_y = int((new_rectangle_coordinates[1, 0] + new_rectangle_coordinates[1, 2]) / 2.0)\n",
    "    #image = cv2.rectangle(image, (centroid_x - 28, centroid_y - 32), (centroid_x + 28, centroid_y + 32), (0, 0, 255), 2)\n",
    "    \n",
    "    image = cv2.rectangle(image, (int(top_left[0][0]), int(top_left[1][0])), (int(bottom_right[0][0]), int(bottom_right[1][0])), (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if(count > 100):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_update(template_frame, current_frame, x_range, y_range, p, thresh, constant, flag):\n",
    "    \n",
    "    # compute the roi of the template\n",
    "    template_frame = template_frame[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "    \n",
    "    # compute derivatives around x and y directions for the current frame\n",
    "    sobelx = cv2.Sobel(current_frame, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "    sobely = cv2.Sobel(current_frame, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "    \n",
    "    count = 0\n",
    "    while(count <= 100):\n",
    "        count = count + 1\n",
    "        \n",
    "        # affine matrix\n",
    "        affine_mat = np.array([[1 + p[0][0], p[2][0], p[4][0]], [p[1][0], 1 + p[3][0], p[5][0]]], dtype = np.float32)\n",
    "        \n",
    "        # warp the image\n",
    "        warped_current_frame = cv2.warpAffine(current_frame, affine_mat, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        warped_current_frame = warped_current_frame[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "        \n",
    "        # warp the sobelx and sobely\n",
    "        warped_sobelx = cv2.warpAffine(sobelx, affine_mat, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        warped_sobely = cv2.warpAffine(sobely, affine_mat, (0, 0), flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "        warped_sobelx = warped_sobelx[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "        warped_sobely = warped_sobely[int(y_range[0]):int(y_range[1]), int(x_range[0]):int(x_range[1])]\n",
    "        warped_sobelx = warped_sobelx.reshape(-1, 1)\n",
    "        warped_sobely = warped_sobely.reshape(-1, 1)\n",
    "        \n",
    "        # calculate error value\n",
    "        error = (template_frame.astype(int) - warped_current_frame.astype(int)).reshape(-1, 1)\n",
    "        \n",
    "        # calculate steep descent value\n",
    "        count = 0\n",
    "        steep_descent = []\n",
    "        for y in range(y_range[0], y_range[1]):\n",
    "            for x in range(x_range[0], x_range[1]):\n",
    "                jacobian = [x * warped_sobelx[count][0], x * warped_sobely[count][0], y * warped_sobelx[count][0], y * warped_sobely[count][0], warped_sobelx[count][0], warped_sobely[count][0]]\n",
    "                steep_descent.append(jacobian)\n",
    "                count = count + 1\n",
    "        steep_descent = np.array(steep_descent)\n",
    "        \n",
    "        # calculate the hessian matrix and its inverse\n",
    "        sd_param_matrix = np.dot(steep_descent.T, error)\n",
    "        hessian_matrix = np.dot(steep_descent.T, steep_descent)\n",
    "        hessian_matrix_inv = np.linalg.pinv(hessian_matrix)\n",
    "        \n",
    "        # calculate delta_p and update p matrix\n",
    "        delta_p = np.dot(hessian_matrix_inv, sd_param_matrix)\n",
    "        p_norm = np.linalg.norm(delta_p)\n",
    "        p = np.reshape(p, (6, 1))\n",
    "        delta_p = constant * delta_p\n",
    "        p = p + delta_p\n",
    "        \n",
    "        if(flag and p_norm < thresh):\n",
    "            break\n",
    "        \n",
    "    # return the updated p and rectangle cooridnates\n",
    "    affine_mat = np.array([[1 + p[0][0], p[2][0], p[4][0]], [p[1][0], 1 + p[3][0], p[5][0]]], dtype = np.float32)\n",
    "    top_left = np.array([[x_range[0]], [y_range[0]], [1]])\n",
    "    bottom_right = np.array([[x_range[1]], [y_range[1]], [1]])\n",
    "    updated_top_left = np.dot(affine_mat, top_left)\n",
    "    updated_bottom_right = np.dot(affine_mat, bottom_right)\n",
    "    return (p, updated_top_left, updated_bottom_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
